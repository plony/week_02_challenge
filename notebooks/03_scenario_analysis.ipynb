{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "120d7ee3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scripts.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Add the 'scripts' directory to the Python path\u001b[39;00m\n\u001b[32m     10\u001b[39m sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir, \u001b[33m'\u001b[39m\u001b[33mscripts\u001b[39m\u001b[33m'\u001b[39m)))\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscripts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m preprocess_text \u001b[38;5;66;03m# For manual keyword checks\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Configure plotting style\u001b[39;00m\n\u001b[32m     14\u001b[39m sns.set_style(\u001b[33m\"\u001b[39m\u001b[33mwhitegrid\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'scripts.utils'"
     ]
    }
   ],
   "source": [
    "# notebooks/03_scenario_analysis.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add the 'scripts' directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir, 'scripts')))\n",
    "from scripts.utils import preprocess_text # For manual keyword checks\n",
    "\n",
    "# Configure plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Load the analyzed data\n",
    "processed_data_dir = os.path.join(os.path.abspath(''), os.pardir, 'data', 'processed')\n",
    "input_filepath = os.path.join(processed_data_dir, 'fintech_app_reviews_analyzed.csv')\n",
    "\n",
    "if not os.path.exists(input_filepath):\n",
    "    print(f\"Error: Analyzed data file not found at {input_filepath}. Please run 02_sentiment_thematic_analysis.ipynb first.\")\n",
    "    df_analyzed = pd.DataFrame() # Create an empty DataFrame to avoid errors\n",
    "else:\n",
    "    df_analyzed = pd.read_csv(input_filepath)\n",
    "    print(f\"Loaded {len(df_analyzed)} analyzed reviews.\")\n",
    "    \n",
    "    # Ensure 'Processed_Reviews_Tokens' and 'Extracted_Keywords' are parsed as lists\n",
    "    # They were stored as stringified lists in CSV, need to convert back\n",
    "    import ast # For safely evaluating string representations of lists\n",
    "    df_analyzed['Processed_Reviews_Tokens'] = df_analyzed['Processed_Reviews_Tokens'].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n",
    "    df_analyzed['Extracted_Keywords'] = df_analyzed['Extracted_Keywords'].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n",
    "\n",
    "\n",
    "print(\"\\n--- Scenario 1: Retaining Users (Slow Loading during Transfers) ---\")\n",
    "# CBE has 4.4, BOA 2.8, Dashen 4.0\n",
    "# Users complain about slow loading during transfers. Analyze if this is a broader issue.\n",
    "\n",
    "# Keywords related to slow loading/transfers\n",
    "slow_transfer_keywords = ['slow', 'loading', 'lag', 'transfer', 'send money', 'delay', 'time', 'network']\n",
    "\n",
    "# Filter reviews containing these keywords (case-insensitive search in original text)\n",
    "slow_transfer_reviews = df_analyzed[\n",
    "    df_analyzed['Review Text'].str.contains('|'.join(slow_transfer_keywords), case=False, na=False)\n",
    "].copy()\n",
    "\n",
    "if not slow_transfer_reviews.empty:\n",
    "    print(f\"\\nTotal reviews mentioning slow loading/transfers: {len(slow_transfer_reviews)}\")\n",
    "\n",
    "    # Sentiment distribution for these reviews\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.countplot(data=slow_transfer_reviews, x='Sentiment', palette='coolwarm', order=['Negative', 'Neutral', 'Positive'])\n",
    "    plt.title('Sentiment of \"Slow Loading/Transfer\" Related Reviews')\n",
    "    plt.xlabel('Sentiment')\n",
    "    plt.ylabel('Number of Reviews')\n",
    "    plt.show()\n",
    "\n",
    "    # Breakdown by bank\n",
    "    print(\"\\nSlow Loading/Transfer Complaints by Bank:\")\n",
    "    bank_complaints = slow_transfer_reviews.groupby('Bank/App Name')['Sentiment'].value_counts().unstack(fill_value=0)\n",
    "    bank_complaints['Total'] = bank_complaints.sum(axis=1)\n",
    "    bank_complaints['Negative_Ratio'] = bank_complaints['Negative'] / bank_complaints['Total']\n",
    "    print(bank_complaints.sort_values(by='Negative_Ratio', ascending=False))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=bank_complaints.reset_index(), x='Bank/App Name', y='Negative_Ratio', palette='viridis')\n",
    "    plt.title('Ratio of Negative Sentiment for \"Slow Loading/Transfer\" Reviews by Bank')\n",
    "    plt.xlabel('Bank/App Name')\n",
    "    plt.ylabel('Ratio of Negative Reviews')\n",
    "    plt.show()\n",
    "\n",
    "    # Insights and Recommendations for Scenario 1\n",
    "    print(\"\\n**Scenario 1 Insights & Recommendations:**\")\n",
    "    print(\"The analysis of 'slow loading/transfer' complaints shows:\")\n",
    "    print(f\"- Overall, {slow_transfer_reviews['Sentiment'].value_counts().get('Negative', 0)} out of {len(slow_transfer_reviews)} reviews mentioning these issues are negative, indicating a significant pain point.\")\n",
    "    print(\"- While CBE has a high overall rating, it still receives complaints about this issue, suggesting underlying technical challenges that affect user experience even for its generally satisfied users.\")\n",
    "    print(\"- BOA shows the highest ratio of negative sentiment related to this theme, aligning with its lower overall rating, implying this is a critical area for improvement.\")\n",
    "    print(\"\\nRecommendations:\")\n",
    "    print(\"1. **Deep Technical Audit:** All banks, especially BOA, should conduct a deep technical audit of their transaction processing systems, API response times, and network infrastructure, particularly during peak hours.\")\n",
    "    print(\"2. **Targeted Performance Optimization:** Focus on optimizing the performance of critical paths like money transfers and balance inquiries. Implement caching mechanisms and optimize database queries.\")\n",
    "    print(\"3. **Proactive Communication:** Inform users about known performance issues and when fixes are deployed. Implement in-app progress indicators for transfers to manage user expectations.\")\n",
    "else:\n",
    "    print(\"No reviews found mentioning 'slow loading' or 'transfer' related issues.\")\n",
    "\n",
    "print(\"\\n--- Scenario 2: Enhancing Features ---\")\n",
    "# Extract desired features (e.g., transfer, fingerprint login, faster loading times)\n",
    "# Recommend how each bank can stay competitive.\n",
    "\n",
    "# Filter for reviews mentioning feature requests (positive sentiment for new features)\n",
    "# Or reviews that directly ask for a feature (e.g., \"I wish it had...\")\n",
    "feature_request_keywords = ['feature', 'add', 'wish', 'want', 'suggest', 'improve', 'need', 'require', 'update']\n",
    "\n",
    "# Analyze sentiment for reviews where 'Identified_Theme' is 'Feature Requests'\n",
    "feature_reviews = df_analyzed[df_analyzed['Identified_Theme'].str.contains('Feature Requests', na=False)].copy()\n",
    "\n",
    "if not feature_reviews.empty:\n",
    "    print(f\"\\nTotal reviews categorized as Feature Requests: {len(feature_reviews)}\")\n",
    "\n",
    "    # Extract common keywords/n-grams from feature request reviews\n",
    "    all_feature_request_words = [word for sublist in feature_reviews['Processed_Reviews_Tokens'] for word in sublist]\n",
    "    feature_word_freq = pd.Series(all_feature_request_words).value_counts().head(20)\n",
    "\n",
    "    print(\"\\nTop 20 Keywords in Feature Request Reviews:\")\n",
    "    print(feature_word_freq)\n",
    "\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.barplot(x=feature_word_freq.index, y=feature_word_freq.values, palette='crest')\n",
    "    plt.title('Top Keywords in Feature Request Reviews')\n",
    "    plt.xlabel('Keyword')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Breakdown of desired features by bank\n",
    "    print(\"\\nCommon Feature Mentions by Bank:\")\n",
    "    \n",
    "    # We can refine this by looking at specific feature-related keywords within each bank's 'Feature Requests'\n",
    "    desired_features_map = {\n",
    "        'fingerprint login': ['fingerprint', 'biometric', 'faceid', 'login'],\n",
    "        'faster loading': ['fast', 'speed', 'loading', 'quick'],\n",
    "        'bill payment': ['bill', 'pay', 'utility'],\n",
    "        'P2P transfer': ['p2p', 'peer to peer'],\n",
    "        'budgeting tools': ['budget', 'expense', 'track', 'spending']\n",
    "    }\n",
    "\n",
    "    feature_bank_counts = {}\n",
    "    for bank in df_analyzed['Bank/App Name'].unique():\n",
    "        bank_feature_counts = {}\n",
    "        bank_feature_reviews = df_analyzed[(df_analyzed['Bank/App Name'] == bank) & (df_analyzed['Identified_Theme'].str.contains('Feature Requests', na=False))]\n",
    "        \n",
    "        bank_text = ' '.join(bank_feature_reviews['Review Text'].dropna().tolist())\n",
    "        \n",
    "        for feature, keywords in desired_features_map.items():\n",
    "            count = sum(bank_text.lower().count(kw) for kw in keywords)\n",
    "            if count > 0:\n",
    "                bank_feature_counts[feature] = count\n",
    "        feature_bank_counts[bank] = bank_feature_counts\n",
    "\n",
    "    feature_comparison_df = pd.DataFrame(feature_bank_counts).fillna(0).T\n",
    "    print(feature_comparison_df)\n",
    "\n",
    "    # Insights and Recommendations for Scenario 2\n",
    "    print(\"\\n**Scenario 2 Insights & Recommendations:**\")\n",
    "    print(\"Common feature requests across all banks include fingerprint login, faster loading, and budgeting tools.\")\n",
    "    print(\"Recommendations:\")\n",
    "    print(\"1. **Prioritize Biometric Login:** Given the prevalence of 'fingerprint' keywords, all banks should prioritize implementing or improving biometric login (fingerprint/face ID) for enhanced security and convenience.\")\n",
    "    print(\"2. **Focus on Speed:** 'Faster loading' is a recurring request. This reinforces the need for ongoing performance optimization, as discussed in Scenario 1.\")\n",
    "    print(\"3. **Innovation for Competitive Edge:**\")\n",
    "    print(\"   - **CBE:** Leverage its strong user base. Consider introducing advanced features like in-app budgeting tools or personalized financial advice to deepen engagement and retention.\")\n",
    "    print(\"   - **BOA:** Focus on core functionality first, ensuring existing features are robust and performant. Then, add highly requested features like biometric login to address immediate user needs and build trust.\")\n",
    "    print(\"   - **Dashen Bank:** Explore niche features like QR code payments or specific bill payment integrations if user feedback points to these, to differentiate itself in the market.\")\n",
    "else:\n",
    "    print(\"No reviews found categorized as 'Feature Requests'.\")\n",
    "\n",
    "print(\"\\n--- Scenario 3: Managing Complaints ---\")\n",
    "# Cluster and track complaints (e.g., “login error”) to guide AI chatbot integration.\n",
    "\n",
    "# Focus on negative reviews for complaint clustering\n",
    "negative_reviews = df_analyzed[df_analyzed['Sentiment'] == 'Negative'].copy()\n",
    "\n",
    "if not negative_reviews.empty:\n",
    "    print(f\"\\nTotal Negative Reviews for Complaint Analysis: {len(negative_reviews)}\")\n",
    "\n",
    "    # Use 'Identified_Theme' as initial clusters for complaints\n",
    "    print(\"\\nTop Complaint Themes (from Negative Reviews):\")\n",
    "    complaint_theme_counts = negative_reviews['Identified_Theme'].value_counts()\n",
    "    print(complaint_theme_counts)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=complaint_theme_counts.index, y=complaint_theme_counts.values, palette='Reds_d')\n",
    "    plt.title('Top Complaint Themes in Negative Reviews')\n",
    "    plt.xlabel('Complaint Theme')\n",
    "    plt.ylabel('Number of Negative Reviews')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Identify top keywords in critical themes, e.g., 'Account Access Issues'\n",
    "    if 'Account Access Issues' in complaint_theme_counts.index:\n",
    "        access_issue_reviews = negative_reviews[negative_reviews['Identified_Theme'] == 'Account Access Issues']\n",
    "        all_access_words = [word for sublist in access_issue_reviews['Processed_Reviews_Tokens'] for word in sublist]\n",
    "        access_word_freq = pd.Series(all_access_words).value_counts().head(10)\n",
    "        print(\"\\nTop Keywords in 'Account Access Issues' (Negative Reviews):\")\n",
    "        print(access_word_freq)\n",
    "        \n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.barplot(x=access_word_freq.index, y=access_word_freq.values, palette='Blues_d')\n",
    "        plt.title('Top Keywords in Negative \"Account Access Issues\"')\n",
    "        plt.xlabel('Keyword')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Insights and Recommendations for Scenario 3\n",
    "    print(\"\\n**Scenario 3 Insights & Recommendations:**\")\n",
    "    print(\"The dominant complaint themes, especially 'Account Access Issues' and 'Transaction Performance', indicate areas ripe for support automation.\")\n",
    "    print(\"\\nRecommendations for AI Chatbot Integration and Faster Support:\")\n",
    "    print(\"1. **Chatbot Training Data:** Use the identified complaint themes and their associated negative review texts (e.g., reviews related to 'login error', 'transaction failed', 'app crash') as direct training data for the AI chatbot's NLU (Natural Language Understanding) module.\")\n",
    "    print(\"2. **Automated FAQs & Troubleshooting:** Develop automated responses and step-by-step troubleshooting guides for common, high-volume issues like 'login error' or 'OTP not received'. The chatbot should guide users through these processes.\")\n",
    "    print(\"3. **Smart Routing for Complex Issues:** For themes like 'Complex transaction disputes' or 'Security concerns' (which might emerge from more advanced clustering), the chatbot should be trained to identify these and immediately escalate to a human agent, providing the agent with the chat transcript and relevant user data.\")\n",
    "    print(\"4. **Proactive Issue Detection:** Monitor real-time incoming reviews for spikes in specific complaint keywords. If a sudden increase in 'login error' complaints is detected, it could signal a system-wide issue, prompting immediate investigation by engineering teams.\")\n",
    "else:\n",
    "    print(\"No negative reviews found for complaint analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
