{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b48d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/04_reporting_visualizations.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import ast # For literal_eval\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud # For keyword clouds\n",
    "\n",
    "# Configure plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Define output paths for visualizations\n",
    "output_viz_dir = os.path.join(os.path.abspath(''), os.pardir, 'output', 'visualizations')\n",
    "os.makedirs(output_viz_dir, exist_ok=True)\n",
    "\n",
    "# Load the analyzed data\n",
    "processed_data_dir = os.path.join(os.path.abspath(''), os.pardir, 'data', 'processed')\n",
    "input_filepath = os.path.join(processed_data_dir, 'fintech_app_reviews_analyzed.csv')\n",
    "\n",
    "if not os.path.exists(input_filepath):\n",
    "    print(f\"Error: Analyzed data file not found at {input_filepath}. Please run 02_sentiment_thematic_analysis.ipynb first.\")\n",
    "    df_analyzed = pd.DataFrame() # Create an empty DataFrame to avoid errors\n",
    "else:\n",
    "    df_analyzed = pd.read_csv(input_filepath)\n",
    "    print(f\"Loaded {len(df_analyzed)} analyzed reviews.\")\n",
    "    \n",
    "    # Ensure 'Processed_Reviews_Tokens' and 'Extracted_Keywords' are parsed as lists\n",
    "    df_analyzed['Processed_Reviews_Tokens'] = df_analyzed['Processed_Reviews_Tokens'].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n",
    "    df_analyzed['Extracted_Keywords'] = df_analyzed['Extracted_Keywords'].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n",
    "\n",
    "\n",
    "if not df_analyzed.empty:\n",
    "    print(\"\\n--- Generating Visualizations ---\")\n",
    "\n",
    "    # 1. Overall Rating Distribution\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.countplot(data=df_analyzed, x='Rating', palette='viridis')\n",
    "    plt.title('Overall Rating Distribution')\n",
    "    plt.xlabel('Star Rating')\n",
    "    plt.ylabel('Number of Reviews')\n",
    "    plt.savefig(os.path.join(output_viz_dir, 'overall_rating_distribution.png'))\n",
    "    plt.show()\n",
    "\n",
    "    # 2. Sentiment Distribution by Bank\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(data=df_analyzed, x='Bank/App Name', hue='Sentiment', palette='coolwarm', \n",
    "                  order=df_analyzed['Bank/App Name'].value_counts().index,\n",
    "                  hue_order=['Positive', 'Neutral', 'Negative'])\n",
    "    plt.title('Sentiment Distribution by Bank')\n",
    "    plt.xlabel('Bank/App Name')\n",
    "    plt.ylabel('Number of Reviews')\n",
    "    plt.legend(title='Sentiment')\n",
    "    plt.savefig(os.path.join(output_viz_dir, 'sentiment_by_bank.png'))\n",
    "    plt.show()\n",
    "\n",
    "    # 3. Average Sentiment Score by Rating\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.barplot(data=df_analyzed, x='Rating', y='Sentiment_Score', palette='plasma')\n",
    "    plt.title('Average Sentiment Score by Star Rating')\n",
    "    plt.xlabel('Star Rating')\n",
    "    plt.ylabel('Average Sentiment Score (Compound)')\n",
    "    plt.savefig(os.path.join(output_viz_dir, 'avg_sentiment_by_rating.png'))\n",
    "    plt.show()\n",
    "\n",
    "    # 4. Top Themes by Bank (stacked bar chart or heatmap)\n",
    "    theme_bank_counts = df_analyzed.groupby('Bank/App Name')['Identified_Theme'].value_counts(normalize=True).unstack(fill_value=0)\n",
    "    theme_bank_counts = theme_bank_counts.reindex(df_analyzed['Bank/App Name'].value_counts().index) # Order by total reviews\n",
    "    \n",
    "    plt.figure(figsize=(12, 7))\n",
    "    theme_bank_counts.plot(kind='bar', stacked=True, colormap='Paired', ax=plt.gca())\n",
    "    plt.title('Distribution of Themes by Bank (Normalized)')\n",
    "    plt.xlabel('Bank/App Name')\n",
    "    plt.ylabel('Proportion of Reviews')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(title='Theme', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_viz_dir, 'themes_by_bank_stacked.png'))\n",
    "    plt.show()\n",
    "\n",
    "    # 5. Word Cloud of Top Negative Keywords (Overall)\n",
    "    negative_reviews_text = ' '.join(df_analyzed[df_analyzed['Sentiment'] == 'Negative']['Processed_Reviews_Tokens'].explode().dropna().tolist())\n",
    "    \n",
    "    if negative_reviews_text:\n",
    "        wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Reds').generate(negative_reviews_text)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title('Word Cloud of Top Keywords in Negative Reviews')\n",
    "        plt.savefig(os.path.join(output_viz_dir, 'negative_keywords_wordcloud.png'))\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No negative reviews to generate word cloud.\")\n",
    "\n",
    "    # You can add more specific plots based on the scenarios, e.g.:\n",
    "    # - Time series of average sentiment/rating (if enough data and time variations)\n",
    "    # - Bar charts for specific pain points (e.g., 'slow loading' complaints per bank)\n",
    "\n",
    "    print(f\"\\nAll visualizations saved to {output_viz_dir}\")\n",
    "\n",
    "    print(\"\\n--- Report Outline ---\")\n",
    "    print(\"Based on the analysis and visualizations, structure your 4-page final report as follows:\")\n",
    "    print(\"\\n1.  **Executive Summary (Page 1)**\")\n",
    "    print(\"    * Brief overview of findings (e.g., BOA's low sentiment, common pain points).\")\n",
    "    print(\"    * Top 3 actionable recommendations for the banks.\")\n",
    "    print(\"\\n2.  **Introduction & Methodology (Page 1-2)**\")\n",
    "    print(\"    * Project objectives and business context (Omega Consultancy's role).\")\n",
    "    print(\"    * Briefly explain data collection (scraping Google Play), preprocessing, sentiment analysis (VADER/Hugging Face), and thematic analysis (TF-IDF, rule-based).\")\n",
    "    print(\"    * Mention database storage in Oracle.\")\n",
    "    print(\"\\n3.  **Key Findings & Scenario Analysis (Page 2-3)**\")\n",
    "    print(\"    * **Overall App Performance:** Discuss overall sentiment and rating distribution across banks (use relevant plots).\")\n",
    "    print(\"    * **Scenario 1: Retaining Users (Slow Loading/Transfers):**\")\n",
    "    print(\"        * Present findings on slow loading/transfer complaints (e.g., sentiment breakdown, bank comparison).\")\n",
    "    print(\"        * Identify pain points and suggest areas for investigation.\")\n",
    "    print(\"    * **Scenario 2: Enhancing Features:**\")\n",
    "    print(\"        * Show common feature requests (e.g., top keywords from feature reviews).\")\n",
    "    print(\"        * Discuss how each bank can leverage these for competitiveness.\")\n",
    "    print(\"    * **Scenario 3: Managing Complaints:**\")\n",
    "    print(\"        * Present top complaint themes (from negative reviews) and specific keywords (e.g., 'login error').\")\n",
    "    print(\"        * Explain how these insights guide AI chatbot integration and support strategies.\")\n",
    "    print(\"\\n4.  **Actionable Recommendations & Ethical Considerations (Page 4)**\")\n",
    "    print(\"    * Synthesize concrete, actionable recommendations for each bank (CBE, BOA, Dashen) based on drivers and pain points identified.\")\n",
    "    print(\"        * *Example for CBE:* Focus on advanced features like budgeting, minor UI tweaks to maintain high satisfaction.\")\n",
    "    print(\"        * *Example for BOA:* Address critical performance issues (loading times, crashes) and improve customer support responsiveness.\")\n",
    "    print(\"        * *Example for Dashen:* Enhance key features like fingerprint login, improve stability, and address common bugs.\")\n",
    "    print(\"    * **Ethical Considerations:** Briefly note potential biases in review data (e.g., users more likely to leave extreme reviews), the challenge of understanding nuances in short texts, and the importance of responsible data use.\")\n",
    "    print(\"\\n5.  **Conclusion (Page 4)**\")\n",
    "    print(\"    * Summarize the value of data-driven customer experience analytics.\")\n",
    "\n",
    "else:\n",
    "    print(\"No data available to generate visualizations or report outline.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
