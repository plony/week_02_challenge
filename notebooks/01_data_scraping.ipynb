{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d857f821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping reviews for CBE (com.cbe.mobilebanking)...\n",
      "Warning: Only scraped 0 reviews for CBE. Target was 400. Consider re-running or checking app_id.\n",
      "Finished scraping 0 reviews for CBE.\n",
      "Raw reviews for CBE saved to d:\\10academy\\10acadamey\\week_02_challenge\\scripts\\..\\data\\raw\\cbe_reviews_raw.csv\n",
      "Scraping reviews for BOA (com.bog.mobilebanking)...\n",
      "Warning: Only scraped 0 reviews for BOA. Target was 400. Consider re-running or checking app_id.\n",
      "Finished scraping 0 reviews for BOA.\n",
      "Raw reviews for BOA saved to d:\\10academy\\10acadamey\\week_02_challenge\\scripts\\..\\data\\raw\\boa_reviews_raw.csv\n",
      "Scraping reviews for Dashen (com.dashenbank.app)...\n",
      "Warning: Only scraped 0 reviews for Dashen. Target was 400. Consider re-running or checking app_id.\n",
      "Finished scraping 0 reviews for Dashen.\n",
      "Raw reviews for Dashen saved to d:\\10academy\\10acadamey\\week_02_challenge\\scripts\\..\\data\\raw\\dashen_reviews_raw.csv\n",
      "No reviews were scraped. Exiting.\n",
      "No data was scraped or processed.\n",
      "\n",
      "--- Verifying saved CSV ---\n",
      "Output CSV file not found.\n"
     ]
    }
   ],
   "source": [
    "# notebooks/01_data_scraping.ipynb\n",
    "# 1. Import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the 'scripts' directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir, 'scripts')))\n",
    "from scrape_reviews import scrape_and_preprocess_reviews\n",
    "\n",
    "# 2. Define App IDs\n",
    "app_ids = {\n",
    "    \"CBE\": \"com.cbe.mobilebanking\", # Replace with actual CBE App ID\n",
    "    \"BOA\": \"com.bog.mobilebanking\", # Replace with actual BOA App ID\n",
    "    \"Dashen\": \"com.dashenbank.app\" # Replace with actual Dashen Bank App ID\n",
    "}\n",
    "\n",
    "# 3. Define output path\n",
    "processed_data_dir = os.path.join(os.path.abspath(''), os.pardir, 'data', 'processed')\n",
    "output_filepath = os.path.join(processed_data_dir, 'fintech_app_reviews_processed.csv')\n",
    "\n",
    "# 4. Scrape and preprocess data\n",
    "# This calls the function from your script\n",
    "df_raw = scrape_and_preprocess_reviews(app_ids, min_reviews_per_bank=400)\n",
    "\n",
    "# 5. Display basic info and save\n",
    "if not df_raw.empty:\n",
    "    print(\"\\n--- Raw Data Overview (from scraping) ---\")\n",
    "    print(df_raw.head())\n",
    "    print(f\"Total reviews scraped: {len(df_raw)}\")\n",
    "    print(\"Reviews per bank:\")\n",
    "    print(df_raw['Bank/App Name'].value_counts())\n",
    "\n",
    "    # Save to processed data folder\n",
    "    df_raw.to_csv(output_filepath, index=False)\n",
    "    print(f\"\\nProcessed data saved to {output_filepath}\")\n",
    "else:\n",
    "    print(\"No data was scraped or processed.\")\n",
    "\n",
    "# 6. Verify the saved CSV (optional)\n",
    "print(\"\\n--- Verifying saved CSV ---\")\n",
    "if os.path.exists(output_filepath):\n",
    "    df_loaded = pd.read_csv(output_filepath)\n",
    "    print(f\"Loaded {len(df_loaded)} reviews from {output_filepath}\")\n",
    "    print(df_loaded.info())\n",
    "    print(df_loaded.isnull().sum())\n",
    "else:\n",
    "    print(\"Output CSV file not found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
